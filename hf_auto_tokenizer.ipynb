{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alibayram/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# load gemma2 tokenizer from huggingface\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "gemma_tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-2b-it\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GemmaTokenizerFast(name_or_path='gemma_tokenizer', vocab_size=256000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<bos>', 'eos_token': '<eos>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<start_of_turn>', '<end_of_turn>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<eos>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"<bos>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t4: AddedToken(\"<mask>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t5: AddedToken(\"<2mass>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t6: AddedToken(\"[@BOS@]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t7: AddedToken(\"<unused0>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t8: AddedToken(\"<unused1>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t9: AddedToken(\"<unused2>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t10: AddedToken(\"<unused3>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t11: AddedToken(\"<unused4>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t12: AddedToken(\"<unused5>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t13: AddedToken(\"<unused6>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t14: AddedToken(\"<unused7>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t15: AddedToken(\"<unused8>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t16: AddedToken(\"<unused9>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t17: AddedToken(\"<unused10>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t18: AddedToken(\"<unused11>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t19: AddedToken(\"<unused12>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t20: AddedToken(\"<unused13>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t21: AddedToken(\"<unused14>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t22: AddedToken(\"<unused15>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t23: AddedToken(\"<unused16>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t24: AddedToken(\"<unused17>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t25: AddedToken(\"<unused18>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t26: AddedToken(\"<unused19>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t27: AddedToken(\"<unused20>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t28: AddedToken(\"<unused21>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t29: AddedToken(\"<unused22>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t30: AddedToken(\"<unused23>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t31: AddedToken(\"<unused24>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t32: AddedToken(\"<unused25>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t33: AddedToken(\"<unused26>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t34: AddedToken(\"<unused27>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t35: AddedToken(\"<unused28>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t36: AddedToken(\"<unused29>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t37: AddedToken(\"<unused30>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t38: AddedToken(\"<unused31>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t39: AddedToken(\"<unused32>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t40: AddedToken(\"<unused33>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t41: AddedToken(\"<unused34>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t42: AddedToken(\"<unused35>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t43: AddedToken(\"<unused36>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t44: AddedToken(\"<unused37>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t45: AddedToken(\"<unused38>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t46: AddedToken(\"<unused39>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t47: AddedToken(\"<unused40>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t48: AddedToken(\"<unused41>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t49: AddedToken(\"<unused42>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t50: AddedToken(\"<unused43>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t51: AddedToken(\"<unused44>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t52: AddedToken(\"<unused45>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t53: AddedToken(\"<unused46>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t54: AddedToken(\"<unused47>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t55: AddedToken(\"<unused48>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t56: AddedToken(\"<unused49>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t57: AddedToken(\"<unused50>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t58: AddedToken(\"<unused51>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t59: AddedToken(\"<unused52>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t60: AddedToken(\"<unused53>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t61: AddedToken(\"<unused54>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t62: AddedToken(\"<unused55>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t63: AddedToken(\"<unused56>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t64: AddedToken(\"<unused57>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t65: AddedToken(\"<unused58>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t66: AddedToken(\"<unused59>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t67: AddedToken(\"<unused60>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t68: AddedToken(\"<unused61>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t69: AddedToken(\"<unused62>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t70: AddedToken(\"<unused63>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t71: AddedToken(\"<unused64>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t72: AddedToken(\"<unused65>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t73: AddedToken(\"<unused66>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t74: AddedToken(\"<unused67>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t75: AddedToken(\"<unused68>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t76: AddedToken(\"<unused69>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t77: AddedToken(\"<unused70>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t78: AddedToken(\"<unused71>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t79: AddedToken(\"<unused72>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t80: AddedToken(\"<unused73>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t81: AddedToken(\"<unused74>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t82: AddedToken(\"<unused75>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t83: AddedToken(\"<unused76>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t84: AddedToken(\"<unused77>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t85: AddedToken(\"<unused78>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t86: AddedToken(\"<unused79>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t87: AddedToken(\"<unused80>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t88: AddedToken(\"<unused81>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t89: AddedToken(\"<unused82>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t90: AddedToken(\"<unused83>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t91: AddedToken(\"<unused84>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t92: AddedToken(\"<unused85>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t93: AddedToken(\"<unused86>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t94: AddedToken(\"<unused87>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t95: AddedToken(\"<unused88>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t96: AddedToken(\"<unused89>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t97: AddedToken(\"<unused90>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t98: AddedToken(\"<unused91>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t99: AddedToken(\"<unused92>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t100: AddedToken(\"<unused93>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t101: AddedToken(\"<unused94>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t102: AddedToken(\"<unused95>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t103: AddedToken(\"<unused96>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t104: AddedToken(\"<unused97>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t105: AddedToken(\"<unused98>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t106: AddedToken(\"<start_of_turn>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t107: AddedToken(\"<end_of_turn>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t108: AddedToken(\"\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t109: AddedToken(\"\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t110: AddedToken(\"\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t111: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t112: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t113: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t114: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t115: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t116: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t117: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t118: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t119: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t120: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t121: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t122: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t123: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t124: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t125: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t126: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t127: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t128: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t129: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t130: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t131: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t132: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t133: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t134: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t135: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t136: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t137: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t138: AddedToken(\"\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t139: AddedToken(\"▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t140: AddedToken(\"▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t141: AddedToken(\"▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t142: AddedToken(\"▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t143: AddedToken(\"▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t144: AddedToken(\"▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t145: AddedToken(\"▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t146: AddedToken(\"▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t147: AddedToken(\"▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t148: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t149: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t150: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t152: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t153: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t154: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t155: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t156: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t157: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t158: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t159: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t160: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t161: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t162: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t163: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t164: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t165: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t166: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t167: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t168: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t169: AddedToken(\"<table>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t170: AddedToken(\"<caption>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t171: AddedToken(\"<thead>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t172: AddedToken(\"<tbody>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t173: AddedToken(\"<tfoot>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t174: AddedToken(\"<tr>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t175: AddedToken(\"<th>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t176: AddedToken(\"<td>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t177: AddedToken(\"</table>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t178: AddedToken(\"</caption>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t179: AddedToken(\"</thead>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t180: AddedToken(\"</tbody>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t181: AddedToken(\"</tfoot>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t182: AddedToken(\"</tr>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t183: AddedToken(\"</th>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t184: AddedToken(\"</td>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t185: AddedToken(\"<h1>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t186: AddedToken(\"<h2>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t187: AddedToken(\"<h3>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t188: AddedToken(\"<h4>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t189: AddedToken(\"<h5>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t190: AddedToken(\"<h6>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t191: AddedToken(\"<blockquote>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t192: AddedToken(\"</h1>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t193: AddedToken(\"</h2>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t194: AddedToken(\"</h3>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t195: AddedToken(\"</h4>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t196: AddedToken(\"</h5>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t197: AddedToken(\"</h6>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t198: AddedToken(\"</blockquote>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t199: AddedToken(\"<strong>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t200: AddedToken(\"<em>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t201: AddedToken(\"<b>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t202: AddedToken(\"<i>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t203: AddedToken(\"<u>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t204: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t205: AddedToken(\"<sub>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t206: AddedToken(\"<sup>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t207: AddedToken(\"<code>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t208: AddedToken(\"</strong>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t209: AddedToken(\"</em>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t210: AddedToken(\"</b>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t211: AddedToken(\"</i>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t212: AddedToken(\"</u>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t213: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t214: AddedToken(\"</sub>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t215: AddedToken(\"</sup>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t216: AddedToken(\"</code>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255968: AddedToken(\"[toxicity=0]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255969: AddedToken(\"\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255970: AddedToken(\"\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255971: AddedToken(\"\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255972: AddedToken(\"\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255973: AddedToken(\"\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255974: AddedToken(\"\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255975: AddedToken(\"\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255976: AddedToken(\"\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255977: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255978: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255979: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255980: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255981: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255982: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255983: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255984: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255985: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255986: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255987: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255988: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255989: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255990: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255991: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255992: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255993: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255994: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255995: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255996: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255997: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255998: AddedToken(\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t255999: AddedToken(\"<unused99>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttt = AutoTokenizer.from_pretrained(\"gemma_tokenizer\")\n",
    "ttt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gemma_tokenizer/tokenizer_config.json',\n",
       " 'gemma_tokenizer/special_tokens_map.json',\n",
       " 'gemma_tokenizer/tokenizer.model',\n",
       " 'gemma_tokenizer/added_tokens.json',\n",
       " 'gemma_tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemma_tokenizer.save_pretrained(\"gemma_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108508</th>\n",
       "      <td>ew</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157965</th>\n",
       "      <td>bu</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106397</th>\n",
       "      <td>ark</td>\n",
       "      <td>1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172922</th>\n",
       "      <td>})</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14667</th>\n",
       "      <td>▁res</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20537</th>\n",
       "      <td>▁ag</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83476</th>\n",
       "      <td>▁tra</td>\n",
       "      <td>1006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102932</th>\n",
       "      <td>▁cont</td>\n",
       "      <td>1007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156301</th>\n",
       "      <td>▁et</td>\n",
       "      <td>1008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>▁some</td>\n",
       "      <td>1009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123711</th>\n",
       "      <td>pro</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14453</th>\n",
       "      <td>но</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125276</th>\n",
       "      <td>ga</td>\n",
       "      <td>1012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152999</th>\n",
       "      <td>▁if</td>\n",
       "      <td>1013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238381</th>\n",
       "      <td>ings</td>\n",
       "      <td>1014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207063</th>\n",
       "      <td>▁imp</td>\n",
       "      <td>1015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155329</th>\n",
       "      <td>AT</td>\n",
       "      <td>1016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175558</th>\n",
       "      <td>min</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148490</th>\n",
       "      <td>cri</td>\n",
       "      <td>1018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218419</th>\n",
       "      <td>▁fo</td>\n",
       "      <td>1019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107659</th>\n",
       "      <td>del</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48615</th>\n",
       "      <td>up</td>\n",
       "      <td>1021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250181</th>\n",
       "      <td>old</td>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122984</th>\n",
       "      <td>ob</td>\n",
       "      <td>1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144948</th>\n",
       "      <td>▁their</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155912</th>\n",
       "      <td>gra</td>\n",
       "      <td>1025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211279</th>\n",
       "      <td>▁ri</td>\n",
       "      <td>1026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57627</th>\n",
       "      <td>▁Re</td>\n",
       "      <td>1027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193970</th>\n",
       "      <td>AR</td>\n",
       "      <td>1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20175</th>\n",
       "      <td>ef</td>\n",
       "      <td>1029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53214</th>\n",
       "      <td>ST</td>\n",
       "      <td>1030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96131</th>\n",
       "      <td>ен</td>\n",
       "      <td>1031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17248</th>\n",
       "      <td>now</td>\n",
       "      <td>1032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104365</th>\n",
       "      <td>lan</td>\n",
       "      <td>1033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49541</th>\n",
       "      <td>▁fe</td>\n",
       "      <td>1034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212132</th>\n",
       "      <td>ular</td>\n",
       "      <td>1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18354</th>\n",
       "      <td>▁bo</td>\n",
       "      <td>1036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177269</th>\n",
       "      <td>cre</td>\n",
       "      <td>1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175876</th>\n",
       "      <td>ener</td>\n",
       "      <td>1038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160692</th>\n",
       "      <td>fe</td>\n",
       "      <td>1039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         token    id\n",
       "108508      ew  1000\n",
       "157965      bu  1001\n",
       "106397     ark  1002\n",
       "172922      })  1003\n",
       "14667     ▁res  1004\n",
       "20537      ▁ag  1005\n",
       "83476     ▁tra  1006\n",
       "102932   ▁cont  1007\n",
       "156301     ▁et  1008\n",
       "2390     ▁some  1009\n",
       "123711     pro  1010\n",
       "14453       но  1011\n",
       "125276      ga  1012\n",
       "152999     ▁if  1013\n",
       "238381    ings  1014\n",
       "207063    ▁imp  1015\n",
       "155329      AT  1016\n",
       "175558     min  1017\n",
       "148490     cri  1018\n",
       "218419     ▁fo  1019\n",
       "107659     del  1020\n",
       "48615       up  1021\n",
       "250181     old  1022\n",
       "122984      ob  1023\n",
       "144948  ▁their  1024\n",
       "155912     gra  1025\n",
       "211279     ▁ri  1026\n",
       "57627      ▁Re  1027\n",
       "193970      AR  1028\n",
       "20175       ef  1029\n",
       "53214       ST  1030\n",
       "96131       ен  1031\n",
       "17248      now  1032\n",
       "104365     lan  1033\n",
       "49541      ▁fe  1034\n",
       "212132    ular  1035\n",
       "18354      ▁bo  1036\n",
       "177269     cre  1037\n",
       "175876    ener  1038\n",
       "160692      fe  1039"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# get string, int pairs from gemma_tokenizer.vocab\n",
    "\n",
    "gemma_vocab = gemma_tokenizer.get_vocab()\n",
    "\n",
    "vocab_df = pd.DataFrame(gemma_vocab.items(), columns=['token', 'id'])\n",
    "vocab_df = vocab_df.sort_values('id')\n",
    "vocab_df[1000:1040]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemma_tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<pad>': 0,\n",
       " '<bos>': 1,\n",
       " '<eos>': 2,\n",
       " '<unk>': 3,\n",
       " '<mask>': 4,\n",
       " '<2mass>': 5,\n",
       " '[@BOS@]': 6,\n",
       " '<unused0>': 7,\n",
       " '<unused1>': 8,\n",
       " '<unused2>': 9,\n",
       " '<unused3>': 10,\n",
       " '<unused4>': 11,\n",
       " '<unused5>': 12,\n",
       " '<unused6>': 13,\n",
       " '<unused7>': 14,\n",
       " '<unused8>': 15,\n",
       " '<unused9>': 16,\n",
       " '<unused10>': 17,\n",
       " '<unused11>': 18,\n",
       " '<unused12>': 19,\n",
       " '<unused13>': 20,\n",
       " '<unused14>': 21,\n",
       " '<unused15>': 22,\n",
       " '<unused16>': 23,\n",
       " '<unused17>': 24,\n",
       " '<unused18>': 25,\n",
       " '<unused19>': 26,\n",
       " '<unused20>': 27,\n",
       " '<unused21>': 28,\n",
       " '<unused22>': 29,\n",
       " '<unused23>': 30,\n",
       " '<unused24>': 31,\n",
       " '<unused25>': 32,\n",
       " '<unused26>': 33,\n",
       " '<unused27>': 34,\n",
       " '<unused28>': 35,\n",
       " '<unused29>': 36,\n",
       " '<unused30>': 37,\n",
       " '<unused31>': 38,\n",
       " '<unused32>': 39,\n",
       " '<unused33>': 40,\n",
       " '<unused34>': 41,\n",
       " '<unused35>': 42,\n",
       " '<unused36>': 43,\n",
       " '<unused37>': 44,\n",
       " '<unused38>': 45,\n",
       " '<unused39>': 46,\n",
       " '<unused40>': 47,\n",
       " '<unused41>': 48,\n",
       " '<unused42>': 49,\n",
       " '<unused43>': 50,\n",
       " '<unused44>': 51,\n",
       " '<unused45>': 52,\n",
       " '<unused46>': 53,\n",
       " '<unused47>': 54,\n",
       " '<unused48>': 55,\n",
       " '<unused49>': 56,\n",
       " '<start_of_turn>': 57,\n",
       " '<end_of_turn>': 58}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = {}\n",
    "\n",
    "unk_token = '<unk>'\n",
    "spl_tokens = ['<bos>', '<eos>', '<unk>', '<pad>', '<start_of_turn>', '<end_of_turn>']\n",
    "\n",
    "vocab['<pad>'] = 0\n",
    "vocab['<bos>'] = 1\n",
    "vocab['<eos>'] = 2\n",
    "vocab['<unk>'] = 3\n",
    "vocab['<mask>'] = 4\n",
    "vocab['<2mass>'] = 5\n",
    "vocab['[@BOS@]'] = 6\n",
    "for i in range(50):\n",
    "    vocab[f'<unused{i}>'] = i + 7\n",
    "vocab['<start_of_turn>'] = 57\n",
    "vocab['<end_of_turn>'] = 58\n",
    "\n",
    "vocab\n",
    "\n",
    "#spl_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'A', 'aba', 'Aba', 'abadi', 'Abadi', 'abaküs', 'Abaküs', 'aban', 'Aban']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predefined_words = []\n",
    "with open(\"veri/first_12500_titled.txt\") as f:\n",
    "    for line in f:\n",
    "        # remove newline character\n",
    "        if line.strip() != \"\":\n",
    "          predefined_words.append(line.strip())\n",
    "predefined_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n"
     ]
    }
   ],
   "source": [
    "ekler = [\n",
    "    \"lık\", \"lik\", \"luk\", \"lük\",\n",
    "    \"lı\", \"li\", \"lu\", \"lü\",\n",
    "    \"sız\", \"siz\", \"suz\", \"süz\",\n",
    "    \"cı\", \"ci\", \"cu\", \"cü\",\n",
    "    \"çı\", \"çi\", \"çu\", \"çü\",\n",
    "    \"cık\", \"cik\", \"cuk\", \"cük\",\n",
    "    \"çık\", \"çik\", \"çuk\", \"çük\",\n",
    "    \"ca\", \"ce\",\n",
    "    \"ça\", \"çe\",\n",
    "    \"daş\", \"deş\",\n",
    "    \"taş\", \"teş\",\n",
    "    \"ncı\", \"nci\", \"ncu\", \"ncü\",\n",
    "    \"ar\", \"er\",\n",
    "    \"şar\", \"şer\",\n",
    "    \"sal\", \"sel\",\n",
    "    \"tı\", \"ti\", \"tu\", \"tü\",\n",
    "    \"aç\", \"eç\",\n",
    "    \"ak\", \"ek\",\n",
    "    \"an\", \"en\",\n",
    "    \"cıl\", \"cil\", \"cul\", \"cül\",\n",
    "    \"çıl\", \"çil\", \"çul\",\n",
    "    \"cileyin\",\n",
    "    \"ç\",\n",
    "    \"gil\", \"gül\", \"kıl\", \"kil\",\n",
    "    \"ge\", \"ka\",\n",
    "    \"kan\", \"ken\",\n",
    "    \"kek\",\n",
    "    \"man\", \"men\",\n",
    "    \"la\",\n",
    "    \"lak\", \"lek\",\n",
    "    \"layın\", \"leyin\",\n",
    "    \"msı\", \"msi\", \"msu\",\n",
    "    \"mtırak\",\n",
    "    \"rak\", \"rek\",\n",
    "    \"sak\", \"sek\",\n",
    "    \"sı\", \"si\", \"su\", \"sü\",\n",
    "    \"şın\", \"şin\",\n",
    "    \"t\",\n",
    "    \"z\",\n",
    "    \"la\", \"le\",\n",
    "    \"al\", \"el\",\n",
    "    \"l\",\n",
    "    \"a\", \"e\",\n",
    "    \"ar\", \"er\",\n",
    "    \"da\", \"de\",\n",
    "    \"k\",\n",
    "    \"kır\", \"kir\", \"kur\", \"kür\",\n",
    "    \"msa\", \"mse\",\n",
    "    \"r\",\n",
    "    \"sa\", \"se\",\n",
    "    \"l\",\n",
    "    \"ma\", \"me\",\n",
    "    \"n\",\n",
    "    \"r\",\n",
    "    \"t\",\n",
    "    \"ş\",\n",
    "    \"dır\", \"dir\", \"dur\", \"dür\",\n",
    "    \"tır\", \"tir\", \"tur\", \"tür\",\n",
    "    \"a\", \"e\",\n",
    "    \"ala\", \"ele\",\n",
    "    \"ar\", \"er\",\n",
    "    \"ı\", \"ü\",\n",
    "    \"k\",\n",
    "    \"k\",\n",
    "    \"p\",\n",
    "    \"a\", \"e\",\n",
    "    \"ağan\", \"eğen\",\n",
    "    \"ak\", \"ek\",\n",
    "    \"alak\", \"elek\",\n",
    "    \"amak\", \"emek\",\n",
    "    \"anak\", \"enek\",\n",
    "    \"ca\", \"ce\",\n",
    "    \"ç\",\n",
    "    \"aç\", \"eç\",\n",
    "    \"dı\", \"di\", \"du\", \"dü\",\n",
    "    \"tı\", \"ti\", \"tu\", \"tü\",\n",
    "    \"ga\", \"ge\",\n",
    "    \"gaç\", \"geç\", \"kaç\",\n",
    "    \"gıç\", \"giç\", \"guç\",\n",
    "    \"maca\", \"mece\",\n",
    "    \"maç\", \"meç\",\n",
    "    \"man\", \"men\",\n",
    "    \"mık\", \"mik\", \"muk\",\n",
    "    \"n\",\n",
    "    \"t\",\n",
    "    \"a\", \"e\",\n",
    "    \"ga\", \"ge\",\n",
    "    \"gıç\", \"giç\", \"guç\",\n",
    "    \"n\",\n",
    "    \"t\",\n",
    "    \"lar\", \"ler\", # Çokluk eki\n",
    "    \"mı\", \"mi\", \"mu\", \"mü\", # Soru eki\n",
    "    \"m\", \"n\", \"ı\", \"i\", \"u\", \"ü\", \"sı\", \"si\", \"su\", \"sü\", # İyelik ekleri\n",
    "    \"da\", \"de\", \"ta\", \"te\", # Bulunma hali eki\n",
    "    \"dan\", \"den\", \"tan\", \"ten\", # Ayrılma hali eki\n",
    "    \"ın\", \"in\", \"un\", \"ün\", \"nın\", \"nin\", \"nun\", \"nün\", # İlgi hali eki\n",
    "    \"y\", # Koruyucu ünsüz\n",
    "    \"n\", # Koruyucu ünsüz\n",
    "    \"ki\", # Aitlik eki\n",
    "    \"yor\", \"makta\", \"mede\", # Şimdiki zaman ekleri\n",
    "    \"acak\", \"ecek\", \"acağ\", \"eceğ\", # Gelecek zaman ekleri\n",
    "    \"r\", \"ar\", \"er\", # Geniş zaman ekleri\n",
    "    \"malı\", \"meli\", # Gereklilik kipi eki\n",
    "    \"sa\", \"se\", # Dilek-şart kipi eki\n",
    "    \"a\", \"e\", # İstek kipi eki\n",
    "    \"dı\", \"di\", \"du\", \"dü\", \"tı\", \"ti\", \"tu\", \"tü\", # Görülen geçmiş zaman eki\n",
    "    \"mış\", \"miş\", \"muş\", \"müş\", # Öğrenilen geçmiş zaman eki\n",
    "    \"im\", \"sin\", \"dir\", \"iz\", \"siniz\", \"dirler\", # Ek-fiilin şimdiki/geniş zaman eki\n",
    "    \"dı\", \"di\", \"du\", \"dü\", \"tı\", \"ti\", \"tu\", \"tü\", # Ek-fiilin görülen geçmiş zaman eki\n",
    "    \"mış\", \"miş\", \"muş\", \"müş\", # Ek-fiilin öğrenilen geçmiş zaman eki\n",
    "    \"sa\", \"se\", # Ek-fiilin şart eki\n",
    "    \"yacak\", \"yecek\", # Katmerli birleşik çekim eki\n",
    "    \"miş\", \"miş\", \"muş\", \"müş\", # Katmerli birleşik çekim eki\n",
    "    \"dı\", \"di\", \"du\", \"dü\", \"tı\", \"ti\", \"tu\", \"tü\" # Katmerli birleşik çekim eki\n",
    "]\n",
    "\n",
    "print(len(set(ekler)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25171"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edatlar = [\"gibi\", \"için\", \"kadar\", \"ile\", \"üzere\", \"sanki\", \"den\", \"dolayı\", \"doğru\", \"önce\", \"sonra\", \"karşı\", \"göre\", \"rağmen\", \"beri\", \"üzere\", \"yönelik\", \"ait\"]\n",
    "bağlaçlar = [\"ve\", \"ama\", \"ile\", \"de\", \"çünkü\", \"eğer\", \"fakat\", \"lakin\", \"ki\", \"ya\", \"yahut\", \"ya da\", \"veya\", \"hem\", \"oysa\", \"oysa ki\", \"nitekim\", \"sanki\", \"zira\", \"öyle ki\", \"şu var ki\", \"lâkin\", \"üstelik\", \"ne ... ne\", \"hem ... hem\", \"ister ... ister\", \"gerek ... gerek(se)\", \"ancak\", \"bari\"]\n",
    "ünlemler = [\"ah\", \"ey\", \"oha\", \"öf\", \"hah\", \"ya\", \"aman\", \"hey\", \"hadi\", \"vah\", \"eyvah\", \"uff\", \"of\", \"oh\", \"heyecanla\", \"tamam\", \"çüş\"]\n",
    "cekim_ekleri = [\"ler\", \"lar\", \"i\", \"e\", \"den\", \"de\", \"im\", \"in\", \"i\", \"imiz\", \"iniz\", \"leri\", \"ın\", \"in\", \"un\", \"ün\", \"ca\", \"ce\", \"le\", \"la\", \"r\", \"yor\", \"mekte\", \"di\", \"miş\", \"ecek\", \"meli\", \"malı\", \"se\", \"sa\", \"ayım\", \"ydi\", \"ymiş\", \"yse\", \"dir\", \"m\", \"n\", \"k\", \"iz\", \"siniz\", \"ler\", \"mak\", \"mek\"]\n",
    "yapim_ekleri = [\"lık\", \"li\", \"sız\", \"ci\", \"ce\", \"daş\", \"üncü\", \"msı\", \"cık\", \"tı\", \"cıl\", \"deki\", \"la\", \"al\", \"l\", \"a\", \"ar\", \"da\", \"ık\", \"ımsa\", \"laş\", \"sa\", \"ca\", \"acak\", \"ak\", \"ge\", \"gı\", \"ı\", \"ıcı\", \"ık\", \"ım\", \"nç\", \"ıntı\", \"ır\", \"ış\", \"ma\", \"dır\", \"l\", \"n\", \"t\"]\n",
    "\n",
    "# doldurulacaklar = predefined_words + edatlar + bağlaçlar + ünlemler + cekim_ekleri + yapim_ekleri\n",
    "# TypeError: can only concatenate list (not \"tuple\") to list\n",
    "doldurulacaklar = set()\n",
    "doldurulacaklar.update(predefined_words)\n",
    "doldurulacaklar.update(edatlar)\n",
    "doldurulacaklar.update(bağlaçlar)\n",
    "doldurulacaklar.update(ünlemler)\n",
    "doldurulacaklar.update(cekim_ekleri)\n",
    "doldurulacaklar.update(yapim_ekleri)\n",
    "doldurulacaklar.update(ekler)\n",
    "doldurulacaklar = list(doldurulacaklar)\n",
    "len(doldurulacaklar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "25072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenizer(version=\"1.0\", truncation=None, padding=None, added_tokens=[{\"id\":0, \"content\":\"Çözgü\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":1, \"content\":\"Sınır\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":2, \"content\":\"Şelale\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":3, \"content\":\"Aperitif\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":4, \"content\":\"rakım\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":5, \"content\":\"refleks\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":6, \"content\":\"arz\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":7, \"content\":\"Herek\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":8, \"content\":\"Hasar\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":9, \"content\":\"Sima\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":10, \"content\":\"platonik\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":11, \"content\":\"şalvar\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":12, \"content\":\"Dönüm\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":13, \"content\":\"Mektup\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":14, \"content\":\"Taflan\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":15, \"content\":\"Gökkuzgun\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":16, \"content\":\"biçimli\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":17, \"content\":\"Borik\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":18, \"content\":\"Takt\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":19, \"content\":\"şurup\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":20, \"content\":\"Mukaddime\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":21, \"content\":\"Robotik\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":22, \"content\":\"sabah\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":23, \"content\":\"Gitar\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":24, \"content\":\"Bakan\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":25, \"content\":\"bilim\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":26, \"content\":\"Pırasa\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":27, \"content\":\"mızıka\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":28, \"content\":\"Feyiz\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":29, \"content\":\"uff\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":30, \"content\":\"geveze\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":31, \"content\":\"ansiklopedi\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":32, \"content\":\"şal\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":33, \"content\":\"kokpit\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":34, \"content\":\"Kelaynak\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":35, \"content\":\"Hilafet\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":36, \"content\":\"sinirli\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":37, \"content\":\"tekabül\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":38, \"content\":\"sanatsever\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":39, \"content\":\"silindir\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":40, \"content\":\"Küfe\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":41, \"content\":\"Teslim\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":42, \"content\":\"Ocak\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":43, \"content\":\"paye\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":44, \"content\":\"Başkent\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":45, \"content\":\"sızıntı\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":46, \"content\":\"dile\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":47, \"content\":\"rafine\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":48, \"content\":\"Tezgah\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":49, \"content\":\"Tamir\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50, \"content\":\"rutubet\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":51, \"content\":\"Yüzleş\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":52, \"content\":\"bitişik\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":53, \"content\":\"bumerang\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":54, \"content\":\"tuba\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":55, \"content\":\"Müstesna\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":56, \"content\":\"Söylenti\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":57, \"content\":\"neyzen\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":58, \"content\":\"Bilahare\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":59, \"content\":\"ikbal\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":60, \"content\":\"muhatap\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":61, \"content\":\"Okyanus\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":62, \"content\":\"Kahvehane\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":63, \"content\":\"Soma\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":64, \"content\":\"filizi\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":65, \"content\":\"leyin\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":66, \"content\":\"Çer\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":67, \"content\":\"bağır\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":68, \"content\":\"Refika\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":69, \"content\":\"demirhindi\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":70, \"content\":\"varidat\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":71, \"content\":\"Piyes\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":72, \"content\":\"tahmini\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":73, \"content\":\"revizyonizm\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":74, \"content\":\"kros\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":75, \"content\":\"ayrıca\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":76, \"content\":\"Fetiş\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":77, \"content\":\"Maraton\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":78, \"content\":\"Kalker\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":79, \"content\":\"Fanfar\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":80, \"content\":\"Konsolos\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":81, \"content\":\"Ziraat\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":82, \"content\":\"bakkal\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":83, \"content\":\"tap\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":84, \"content\":\"Hançer\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":85, \"content\":\"Çıyan\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":86, \"content\":\"Tersle\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":87, \"content\":\"Ahlat\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":88, \"content\":\"betimle\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":89, \"content\":\"kakma\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":90, \"content\":\"maarif\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":91, \"content\":\"Bordür\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":92, \"content\":\"Sıvın\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":93, \"content\":\"Mağlubiyet\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":94, \"content\":\"otopsi\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":95, \"content\":\"imge\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":96, \"content\":\"Dolap\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":97, \"content\":\"kolit\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":98, \"content\":\"Poz\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, ...], normalizer=None, pre_tokenizer=Whitespace(), post_processor=None, decoder=None, model=BPE(dropout=None, unk_token=\"<unk>\", continuing_subword_prefix=None, end_of_word_suffix=None, fuse_unk=False, byte_fallback=False, ignore_merges=False, vocab={}, merges=[]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(BPE(unk_token=unk_token))\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "tokenizer.add_tokens(list(doldurulacaklar))\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BpeTrainer(BpeTrainer(min_frequency=16, vocab_size=7001, show_progress=True, special_tokens=[AddedToken(content=\"<bos>\", single_word=False, lstrip=False, rstrip=False, normalized=False, special=True), AddedToken(content=\"<eos>\", single_word=False, lstrip=False, rstrip=False, normalized=False, special=True), AddedToken(content=\"<unk>\", single_word=False, lstrip=False, rstrip=False, normalized=False, special=True), AddedToken(content=\"<pad>\", single_word=False, lstrip=False, rstrip=False, normalized=False, special=True), AddedToken(content=\"<start_of_turn>\", single_word=False, lstrip=False, rstrip=False, normalized=False, special=True), AddedToken(content=\"<end_of_turn>\", single_word=False, lstrip=False, rstrip=False, normalized=False, special=True)], limit_alphabet=1200, initial_alphabet=[], continuing_subword_prefix=None, end_of_word_suffix=None, max_token_length=None, words={}))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = BpeTrainer(special_tokens=spl_tokens, vocab_size=7001, limit_alphabet=1200, min_frequency=16)\n",
    "\n",
    "trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AddedToken(\"<bos>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " AddedToken(\"<eos>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " AddedToken(\"<start_of_turn>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " AddedToken(\"<end_of_turn>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>https://tr.wikipedia.org/wiki/Cengiz%20Han</td>\n",
       "      <td>Cengiz Han</td>\n",
       "      <td>Cengiz Han (doğum adıyla Temuçin,  – 18 Ağusto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>https://tr.wikipedia.org/wiki/Film%20%28anlam%...</td>\n",
       "      <td>Film (anlam ayrımı)</td>\n",
       "      <td>Film şu anlamlara gelebilir:\\n\\n Camlara yapış...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>https://tr.wikipedia.org/wiki/Mustafa%20Suphi</td>\n",
       "      <td>Mustafa Suphi</td>\n",
       "      <td>Mehmed Mustafa Subhi (), kısaca Mustafa Suphi,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>https://tr.wikipedia.org/wiki/Linux</td>\n",
       "      <td>Linux</td>\n",
       "      <td>Linux (telaffuz: Lin-uks); Linux çekirdeğine d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>https://tr.wikipedia.org/wiki/Bol%C5%9Fevizm</td>\n",
       "      <td>Bolşevizm</td>\n",
       "      <td>Bolşevik, çoğunluktan yana anlamına gelen Rusç...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534983</th>\n",
       "      <td>3611624</td>\n",
       "      <td>https://tr.wikipedia.org/wiki/Musculus%20ptery...</td>\n",
       "      <td>Musculus pterygoideus lateralis</td>\n",
       "      <td>ağzı kapatan tek kastır. alt çene ramus'a ve ü...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534984</th>\n",
       "      <td>3611625</td>\n",
       "      <td>https://tr.wikipedia.org/wiki/%C3%87in%20kad%C...</td>\n",
       "      <td>Çin kadın millî futbol takımı</td>\n",
       "      <td>Çin kadın millî futbol takımı, Çin'i uluslarar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534985</th>\n",
       "      <td>3611628</td>\n",
       "      <td>https://tr.wikipedia.org/wiki/Abdurrezak%20KUR...</td>\n",
       "      <td>Abdurrezak KURTULUŞ</td>\n",
       "      <td>1933 yılında Mardin’de doğdu. 1950 yılında Diy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534986</th>\n",
       "      <td>3611631</td>\n",
       "      <td>https://tr.wikipedia.org/wiki/%C4%B0brahim%20T...</td>\n",
       "      <td>İbrahim Turgut</td>\n",
       "      <td>İbrahim Turgut Sayın Cumhurbaşkanı Recep Tayyi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534987</th>\n",
       "      <td>3611637</td>\n",
       "      <td>https://tr.wikipedia.org/wiki/Burcu%20Pirin%C3...</td>\n",
       "      <td>Burcu Pirinçci</td>\n",
       "      <td>Burcu Dindar (evlilik öncesi Pirinçci) (d. 8 Ş...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>534988 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                                url  \\\n",
       "0            10         https://tr.wikipedia.org/wiki/Cengiz%20Han   \n",
       "1            16  https://tr.wikipedia.org/wiki/Film%20%28anlam%...   \n",
       "2            22      https://tr.wikipedia.org/wiki/Mustafa%20Suphi   \n",
       "3            24                https://tr.wikipedia.org/wiki/Linux   \n",
       "4            30       https://tr.wikipedia.org/wiki/Bol%C5%9Fevizm   \n",
       "...         ...                                                ...   \n",
       "534983  3611624  https://tr.wikipedia.org/wiki/Musculus%20ptery...   \n",
       "534984  3611625  https://tr.wikipedia.org/wiki/%C3%87in%20kad%C...   \n",
       "534985  3611628  https://tr.wikipedia.org/wiki/Abdurrezak%20KUR...   \n",
       "534986  3611631  https://tr.wikipedia.org/wiki/%C4%B0brahim%20T...   \n",
       "534987  3611637  https://tr.wikipedia.org/wiki/Burcu%20Pirin%C3...   \n",
       "\n",
       "                                  title  \\\n",
       "0                            Cengiz Han   \n",
       "1                   Film (anlam ayrımı)   \n",
       "2                         Mustafa Suphi   \n",
       "3                                 Linux   \n",
       "4                             Bolşevizm   \n",
       "...                                 ...   \n",
       "534983  Musculus pterygoideus lateralis   \n",
       "534984    Çin kadın millî futbol takımı   \n",
       "534985              Abdurrezak KURTULUŞ   \n",
       "534986                   İbrahim Turgut   \n",
       "534987                   Burcu Pirinçci   \n",
       "\n",
       "                                                     text  \n",
       "0       Cengiz Han (doğum adıyla Temuçin,  – 18 Ağusto...  \n",
       "1       Film şu anlamlara gelebilir:\\n\\n Camlara yapış...  \n",
       "2       Mehmed Mustafa Subhi (), kısaca Mustafa Suphi,...  \n",
       "3       Linux (telaffuz: Lin-uks); Linux çekirdeğine d...  \n",
       "4       Bolşevik, çoğunluktan yana anlamına gelen Rusç...  \n",
       "...                                                   ...  \n",
       "534983  ağzı kapatan tek kastır. alt çene ramus'a ve ü...  \n",
       "534984  Çin kadın millî futbol takımı, Çin'i uluslarar...  \n",
       "534985  1933 yılında Mardin’de doğdu. 1950 yılında Diy...  \n",
       "534986  İbrahim Turgut Sayın Cumhurbaşkanı Recep Tayyi...  \n",
       "534987  Burcu Dindar (evlilik öncesi Pirinçci) (d. 8 Ş...  \n",
       "\n",
       "[534988 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"wikimedia/wikipedia\", \"20231101.tr\")\n",
    "df = ds['train'].to_pandas()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "534988"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_with_title = df['title'] + \" \" + df['text']\n",
    "texts = texts_with_title.to_list()\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30164"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.train_from_iterator(texts, trainer=trainer)\n",
    "tokenizer.save(\"custom_bpe_tokenizer.json\")\n",
    "tokenizer.get_vocab_size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alibayram/Library/Python/3.9/lib/python/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "fast_tokenizer = PreTrainedTokenizerFast(tokenizer_file=\"custom_bpe_tokenizer.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "akademi akademisyen akademisyen ler ve aile leri ile birlikte aktif çalış ı yor lar\n",
      "['akademi', 'akademisyen', 'akademisyen', 'ler', 've', 'aile', 'leri', 'ile', 'birlikte', 'aktif', 'çalış', 'ı', 'yor', 'lar']\n"
     ]
    }
   ],
   "source": [
    "encoded = tokenizer.encode(\"akademi akademisyen akademisyenler ve aileleri ile birlikte aktif çalışıyorlar\")\n",
    "print(tokenizer.decode(encoded.ids))\n",
    "print(fast_tokenizer.tokenize(\"akademi akademisyen akademisyenler ve aileleri ile birlikte aktif çalışıyorlar\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "akademisyen Ada er ve aile Ada er ad il e birlikte aktif çalış Ahize yor la Adalet\n",
    "['akademisyen', 'l', 'er', 've', 'aile', 'l', 'er', 'i', 'il', 'e', 'birlikte', 'aktif', 'çalış', 'ı', 'yor', 'la', 'r']\n",
    "\n",
    "akade mi akademisyen akademisyenler ve aileleri ile birlikte aktif çalışıyor lar\n",
    "['akade', 'mi', 'akademisyen', 'akademisyenler', 've', 'aileleri', 'ile', 'birlikte', 'aktif', 'çalışıyor', 'lar']\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/alibayram/tr_tokenizer/commit/9c11d1b0ebe5e4b44604caff7ea7a9b1d831a42b', commit_message='Upload tokenizer', commit_description='', oid='9c11d1b0ebe5e4b44604caff7ea7a9b1d831a42b', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_tokenizer.push_to_hub(\"alibayram/tr_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C',\n",
       " 'en',\n",
       " 'giz',\n",
       " 'Han',\n",
       " 'C',\n",
       " 'en',\n",
       " 'giz',\n",
       " 'Han',\n",
       " '(',\n",
       " 'doğum',\n",
       " 'ad',\n",
       " 'ı',\n",
       " 'y',\n",
       " 'la',\n",
       " 'Tem',\n",
       " 'uç',\n",
       " 'in',\n",
       " ',',\n",
       " '–',\n",
       " '18',\n",
       " 'Ağustos',\n",
       " '12',\n",
       " '27',\n",
       " '),',\n",
       " 'M',\n",
       " 'o',\n",
       " 'ğ',\n",
       " 'ol',\n",
       " 'İ',\n",
       " 'm',\n",
       " 'para',\n",
       " 'tor',\n",
       " 'lu',\n",
       " 'ğ',\n",
       " 'u',\n",
       " \"'\",\n",
       " 'nun',\n",
       " 'kur',\n",
       " 'u',\n",
       " 'cu',\n",
       " 'su',\n",
       " 've',\n",
       " 'ilk',\n",
       " 'Kağan',\n",
       " 'ı',\n",
       " 'ol',\n",
       " 'an',\n",
       " 'M',\n",
       " 'o',\n",
       " 'ğ',\n",
       " 'ol',\n",
       " 'komutan',\n",
       " 've',\n",
       " 'hükümdar',\n",
       " 'dır',\n",
       " '.',\n",
       " 'Hükümdar',\n",
       " 'lı',\n",
       " 'ğ',\n",
       " 'ı',\n",
       " 'dönem',\n",
       " 'in',\n",
       " 'de',\n",
       " 'gerçekleş',\n",
       " 'tir',\n",
       " 'di',\n",
       " 'ğ',\n",
       " 'i',\n",
       " 'hiçbir',\n",
       " 'savaş',\n",
       " 'ı',\n",
       " 'kaybet',\n",
       " 'mey',\n",
       " 'en',\n",
       " 'C',\n",
       " 'en',\n",
       " 'giz',\n",
       " 'Han',\n",
       " ',',\n",
       " 'dünya',\n",
       " 'tarihi',\n",
       " 'nin',\n",
       " 'en',\n",
       " 'büyük',\n",
       " 'askeri',\n",
       " 'lider',\n",
       " 'leri',\n",
       " 'n',\n",
       " 'den',\n",
       " 'biri',\n",
       " 'si',\n",
       " 'ol',\n",
       " 'arak',\n",
       " 'kabul',\n",
       " 'e',\n",
       " 'dil',\n",
       " 'mekte',\n",
       " 'dir',\n",
       " '.',\n",
       " '13',\n",
       " '.',\n",
       " 'yüzyıl',\n",
       " 'ın',\n",
       " 'baş',\n",
       " 'ın',\n",
       " 'da',\n",
       " 'Orta',\n",
       " 'As',\n",
       " 'ya',\n",
       " \"'\",\n",
       " 'da',\n",
       " 'ki',\n",
       " 'tüm',\n",
       " 'göçebe',\n",
       " 'bozkır',\n",
       " 'kavim',\n",
       " 'leri',\n",
       " 'n',\n",
       " 'i',\n",
       " 'birleş',\n",
       " 'tir',\n",
       " 'ip',\n",
       " 'bir',\n",
       " 'ulus',\n",
       " 'hâ',\n",
       " 'li',\n",
       " 'ne',\n",
       " 'getir',\n",
       " 'erek',\n",
       " 'M',\n",
       " 'o',\n",
       " 'ğ',\n",
       " 'ol',\n",
       " 'siyasi',\n",
       " 'kim',\n",
       " 'li',\n",
       " 'ğ',\n",
       " 'i',\n",
       " 'çat',\n",
       " 'ısı',\n",
       " 'altı',\n",
       " 'n',\n",
       " 'da',\n",
       " 'toplam',\n",
       " 'ış',\n",
       " 'tır',\n",
       " '.',\n",
       " 'C',\n",
       " 'en',\n",
       " 'giz',\n",
       " 'Han',\n",
       " ',',\n",
       " 'hükümdar',\n",
       " 'lı',\n",
       " 'ğ',\n",
       " 'ı',\n",
       " 'dönem',\n",
       " 'in',\n",
       " 'de',\n",
       " ',',\n",
       " '1',\n",
       " '20',\n",
       " '6',\n",
       " '-',\n",
       " '12',\n",
       " '27',\n",
       " 'ara',\n",
       " 'sın',\n",
       " 'da',\n",
       " ',',\n",
       " 'Kuzey',\n",
       " 'Ç',\n",
       " 'in',\n",
       " \"'\",\n",
       " 'deki',\n",
       " 'Batı',\n",
       " 'X',\n",
       " 'i',\n",
       " 'a',\n",
       " 've',\n",
       " 'J',\n",
       " 'in',\n",
       " 'Hanedan',\n",
       " 'ı',\n",
       " ';',\n",
       " 'Türki',\n",
       " 's',\n",
       " 'tan',\n",
       " \"'\",\n",
       " 'da',\n",
       " 'ki',\n",
       " 'Kara',\n",
       " 'H',\n",
       " 'ı',\n",
       " 'tay',\n",
       " ',',\n",
       " 'Mavera',\n",
       " 'ün',\n",
       " 'nehir',\n",
       " ';',\n",
       " 'Hare',\n",
       " 'z',\n",
       " 'm',\n",
       " ',',\n",
       " 'Horasan',\n",
       " 've',\n",
       " 'İ',\n",
       " 'r',\n",
       " 'an',\n",
       " \"'\",\n",
       " 'da',\n",
       " 'ki',\n",
       " 'Hare',\n",
       " 'z',\n",
       " 'm',\n",
       " 'şah',\n",
       " 'lar',\n",
       " ',',\n",
       " 'K',\n",
       " 'af',\n",
       " 'kas',\n",
       " 'ya',\n",
       " \"'\",\n",
       " 'da',\n",
       " 'ki',\n",
       " 'Gür',\n",
       " 'cül',\n",
       " 'er',\n",
       " ',',\n",
       " 'Deş',\n",
       " 't',\n",
       " '-',\n",
       " 'i',\n",
       " 'Kıp',\n",
       " 'çak',\n",
       " \"'\",\n",
       " 'tak',\n",
       " 'i',\n",
       " 'R',\n",
       " 'us',\n",
       " 'K',\n",
       " 'ne',\n",
       " 'z',\n",
       " 'lik',\n",
       " 'leri',\n",
       " ',',\n",
       " 'Kıp',\n",
       " 'çak',\n",
       " 'lar',\n",
       " 'ile',\n",
       " 'İ',\n",
       " 'dil',\n",
       " 'Bul',\n",
       " 'gar',\n",
       " 'lar',\n",
       " 'ı',\n",
       " 'üzer',\n",
       " 'in',\n",
       " 'e',\n",
       " 'sefer',\n",
       " 'ler',\n",
       " 'yap',\n",
       " 'tı',\n",
       " 've',\n",
       " 'imparator',\n",
       " 'lu',\n",
       " 'ğ',\n",
       " 'u',\n",
       " 'dönem',\n",
       " 'in',\n",
       " 'de',\n",
       " 'gerçekleş',\n",
       " 'tir',\n",
       " 'di',\n",
       " 'ğ',\n",
       " 'i',\n",
       " 'hiçbir',\n",
       " 'savaş',\n",
       " 'ı',\n",
       " 'kaybet',\n",
       " 'me',\n",
       " 'di',\n",
       " '.',\n",
       " 'Bu',\n",
       " 'n',\n",
       " 'lar',\n",
       " 'ın',\n",
       " 'son',\n",
       " 'u',\n",
       " 'cunda',\n",
       " 'Pasifik',\n",
       " 'Okyanus',\n",
       " 'u',\n",
       " \"'\",\n",
       " 'n',\n",
       " 'dan',\n",
       " 'Hazar',\n",
       " 'Deniz',\n",
       " 'i',\n",
       " \"'\",\n",
       " 'ne',\n",
       " 've',\n",
       " 'Kara',\n",
       " 'deniz',\n",
       " \"'\",\n",
       " 'in',\n",
       " 'kuzey',\n",
       " 'in',\n",
       " 'e',\n",
       " 'kadar',\n",
       " 'uzan',\n",
       " 'an',\n",
       " 'bir',\n",
       " 'imparator',\n",
       " 'luk',\n",
       " 'kur',\n",
       " 'du',\n",
       " '.',\n",
       " '1',\n",
       " '16',\n",
       " '2',\n",
       " 'civar',\n",
       " 'ın',\n",
       " 'da',\n",
       " 'M',\n",
       " 'o',\n",
       " 'ğ',\n",
       " 'ol',\n",
       " 'is',\n",
       " 'tan',\n",
       " \"'\",\n",
       " 'da',\n",
       " 'ki',\n",
       " 'On',\n",
       " 'on',\n",
       " 'Ne',\n",
       " 'h',\n",
       " 'r',\n",
       " 'i',\n",
       " 'yakı',\n",
       " 'n',\n",
       " 'lar',\n",
       " 'ın',\n",
       " 'da',\n",
       " 'doğ',\n",
       " 'du',\n",
       " 'ğ',\n",
       " 'u',\n",
       " 'düşün',\n",
       " 'ü',\n",
       " 'le',\n",
       " 'n',\n",
       " 'C',\n",
       " 'en',\n",
       " 'giz',\n",
       " 'Han',\n",
       " \"'\",\n",
       " 'ın',\n",
       " 'gerçek',\n",
       " 'ad',\n",
       " 'ı',\n",
       " \"''\",\n",
       " 'Tem',\n",
       " 'uç',\n",
       " 'in',\n",
       " \"''\",\n",
       " 'dir',\n",
       " '.',\n",
       " 'Baba',\n",
       " 'sı',\n",
       " 'Ye',\n",
       " 'sü',\n",
       " 'ge',\n",
       " 'y',\n",
       " ',',\n",
       " 'düşman',\n",
       " 'bir',\n",
       " 'kabile',\n",
       " 'ol',\n",
       " 'an',\n",
       " 'Tatar',\n",
       " 'lar',\n",
       " 'taraf',\n",
       " 'ın',\n",
       " 'dan',\n",
       " 'zehirle',\n",
       " 'nere',\n",
       " 'k',\n",
       " 'öl',\n",
       " 'dür',\n",
       " 'ü',\n",
       " 'l',\n",
       " 'düğün',\n",
       " 'de',\n",
       " 'Tem',\n",
       " 'uç',\n",
       " 'in',\n",
       " 'henüz',\n",
       " '9',\n",
       " 'yaş',\n",
       " 'ın',\n",
       " 'da',\n",
       " 'y',\n",
       " 'dı',\n",
       " '.',\n",
       " 'Tem',\n",
       " 'uç',\n",
       " 'in',\n",
       " \"'\",\n",
       " 'in',\n",
       " 'kabile',\n",
       " 'si',\n",
       " ',',\n",
       " 'küçük',\n",
       " 'yaş',\n",
       " 'tak',\n",
       " 'i',\n",
       " 'bir',\n",
       " 'ç',\n",
       " 'o',\n",
       " 'cu',\n",
       " 'ğ',\n",
       " 'un',\n",
       " 'lider',\n",
       " 'li',\n",
       " 'ğ',\n",
       " 'in',\n",
       " 'i',\n",
       " 'kabul',\n",
       " 'et',\n",
       " 'me',\n",
       " 'di',\n",
       " 've',\n",
       " 'kar',\n",
       " 'deş',\n",
       " 'leri',\n",
       " 've',\n",
       " 'anne',\n",
       " 'si',\n",
       " 'y',\n",
       " 'le',\n",
       " 'birlikte',\n",
       " 'on',\n",
       " 'lar',\n",
       " 'ı',\n",
       " 'ölüm',\n",
       " 'e',\n",
       " 'terk',\n",
       " 'eder',\n",
       " 'ek',\n",
       " 'kabile',\n",
       " 'den',\n",
       " 'sür',\n",
       " 'dü',\n",
       " 'ler',\n",
       " '.',\n",
       " 'M',\n",
       " 'o',\n",
       " 'ğ',\n",
       " 'ol',\n",
       " 'is',\n",
       " 'tan',\n",
       " \"'\",\n",
       " 'ın',\n",
       " 'acı',\n",
       " 'ma',\n",
       " 'sız',\n",
       " 'bozkır',\n",
       " 'lar',\n",
       " 'ın',\n",
       " 'da',\n",
       " 'kaçar',\n",
       " 'ak',\n",
       " 've',\n",
       " 'saklan',\n",
       " 'arak',\n",
       " 'hayat',\n",
       " 'ta',\n",
       " 'kal',\n",
       " 'maya',\n",
       " 'çalış',\n",
       " 'tı',\n",
       " 'lar',\n",
       " '.',\n",
       " 'Tem',\n",
       " 'uç',\n",
       " 'in',\n",
       " 'daha',\n",
       " 'küçücük',\n",
       " 'bir',\n",
       " 'çocuk',\n",
       " 'ken',\n",
       " ',',\n",
       " 'avla',\n",
       " 'dı',\n",
       " 'k',\n",
       " 'lar',\n",
       " 'ı',\n",
       " 'bir',\n",
       " 'hayvan',\n",
       " 'ı',\n",
       " 'paylaş',\n",
       " 'mak',\n",
       " 'istem',\n",
       " 'ey',\n",
       " 'en',\n",
       " 'üvey',\n",
       " 'kar',\n",
       " 'deş',\n",
       " 'in',\n",
       " 'i',\n",
       " 'çık',\n",
       " 'an',\n",
       " 'bir',\n",
       " 'kavga',\n",
       " 'son',\n",
       " 'u',\n",
       " 'cu',\n",
       " 'öl',\n",
       " 'dür',\n",
       " 'dü',\n",
       " '.',\n",
       " '16',\n",
       " 'yaş',\n",
       " 'ın',\n",
       " 'a',\n",
       " 'gel',\n",
       " 'di',\n",
       " 'ğ',\n",
       " 'in',\n",
       " 'de',\n",
       " ',',\n",
       " 'daha',\n",
       " 'önce',\n",
       " 'den',\n",
       " 'yap',\n",
       " 'tıkla',\n",
       " 'r',\n",
       " 'ı',\n",
       " 'bir',\n",
       " 'anlaşma',\n",
       " 'saye',\n",
       " 'sin',\n",
       " 'de',\n",
       " 'nüfuz',\n",
       " 'lu',\n",
       " 'bir',\n",
       " 'kabile',\n",
       " 'den',\n",
       " 'ol',\n",
       " 'an',\n",
       " 'B',\n",
       " 'ört',\n",
       " 'e',\n",
       " 'is',\n",
       " 'mi',\n",
       " 'n',\n",
       " 'de',\n",
       " 'biri',\n",
       " 'si',\n",
       " 'y',\n",
       " 'le',\n",
       " 'evlen',\n",
       " 'di',\n",
       " '.',\n",
       " 'Henüz',\n",
       " '20',\n",
       " 'yaş',\n",
       " 'ın',\n",
       " 'a',\n",
       " 'gel',\n",
       " 'di',\n",
       " 'ğ',\n",
       " 'in',\n",
       " 'de',\n",
       " ',',\n",
       " 'tüm',\n",
       " 'M',\n",
       " 'o',\n",
       " 'ğ',\n",
       " 'ol',\n",
       " 'is',\n",
       " 'tan',\n",
       " \"'\",\n",
       " 'da',\n",
       " 'tan',\n",
       " 'ın',\n",
       " 'an',\n",
       " 've',\n",
       " 'saygı',\n",
       " 'duyu',\n",
       " 'la',\n",
       " 'n',\n",
       " 'bir',\n",
       " 'komutan',\n",
       " 'hal',\n",
       " 'in',\n",
       " 'e',\n",
       " 'gel',\n",
       " 'mey',\n",
       " 'i',\n",
       " 'başar',\n",
       " 'mış',\n",
       " 'tı',\n",
       " '.',\n",
       " 'M',\n",
       " 'o',\n",
       " 'ğ',\n",
       " 'ol',\n",
       " 'is',\n",
       " 'tan',\n",
       " \"'\",\n",
       " 'da',\n",
       " 'ki',\n",
       " 'göçebe',\n",
       " 'kavim',\n",
       " 'leri',\n",
       " 'bir',\n",
       " 'er',\n",
       " 'bir',\n",
       " 'er',\n",
       " 'kendi',\n",
       " 'bay',\n",
       " 'r',\n",
       " 'ağ',\n",
       " 'ı',\n",
       " 'altı',\n",
       " 'n',\n",
       " 'da',\n",
       " 'birleş',\n",
       " 'tir',\n",
       " 'di',\n",
       " '.',\n",
       " '1',\n",
       " '20',\n",
       " '6',\n",
       " 'yıl',\n",
       " 'ın',\n",
       " 'a',\n",
       " 'gelin',\n",
       " 'di',\n",
       " 'ğ',\n",
       " 'in',\n",
       " 'de',\n",
       " 'M',\n",
       " 'o',\n",
       " 'ğ',\n",
       " 'ol',\n",
       " 'is',\n",
       " 'tan',\n",
       " \"'\",\n",
       " 'da',\n",
       " 'birlik',\n",
       " 'sağ',\n",
       " 'la',\n",
       " 'n',\n",
       " 'mış',\n",
       " 'tı',\n",
       " '.',\n",
       " '1',\n",
       " '20',\n",
       " '6',\n",
       " 'yıl',\n",
       " 'ın',\n",
       " 'ın',\n",
       " 'ilkbahar',\n",
       " 'ın',\n",
       " 'da',\n",
       " 'On',\n",
       " 'on',\n",
       " 'Ne',\n",
       " 'h',\n",
       " 'r',\n",
       " 'i',\n",
       " \"'\",\n",
       " 'nin',\n",
       " 'yakı',\n",
       " 'n',\n",
       " 'lar',\n",
       " 'ın',\n",
       " 'da',\n",
       " ',',\n",
       " 'kendi',\n",
       " 'sin',\n",
       " 'e',\n",
       " 'bağla',\n",
       " 'n',\n",
       " 'mış',\n",
       " 'ol',\n",
       " 'an',\n",
       " 'bütün',\n",
       " 'kabile',\n",
       " 'leri',\n",
       " 'bir',\n",
       " 'ara',\n",
       " 'ya',\n",
       " 'getir',\n",
       " 'erek',\n",
       " 'büyük',\n",
       " 'bir',\n",
       " 'kurultay',\n",
       " 'topla',\n",
       " 'dı',\n",
       " '.',\n",
       " 'Tüm',\n",
       " 'göçebe',\n",
       " 'kavim',\n",
       " 'leri',\n",
       " 'birleş',\n",
       " 'tire',\n",
       " 'n',\n",
       " 'Tem',\n",
       " 'uç',\n",
       " 'in',\n",
       " 'tek',\n",
       " 'bir',\n",
       " 'ulus',\n",
       " 'yarat',\n",
       " 'mış',\n",
       " 'tı',\n",
       " 've',\n",
       " 'bu',\n",
       " 'ulus',\n",
       " 'a',\n",
       " '“',\n",
       " 'M',\n",
       " 'o',\n",
       " 'ğ',\n",
       " 'ol',\n",
       " 'Ulus',\n",
       " 'u',\n",
       " '”',\n",
       " 'ad',\n",
       " 'ın',\n",
       " 'ı',\n",
       " 'ver',\n",
       " 'di',\n",
       " '.',\n",
       " 'Bu',\n",
       " 'kurultay',\n",
       " 'da',\n",
       " 'Tem',\n",
       " 'uç',\n",
       " 'in',\n",
       " ',',\n",
       " 'daha',\n",
       " 'önce',\n",
       " 'den',\n",
       " 'al',\n",
       " 'dı',\n",
       " 'ğ',\n",
       " 'ı',\n",
       " '“',\n",
       " 'Kağan',\n",
       " '”',\n",
       " 'unvan',\n",
       " 'ın',\n",
       " 'a',\n",
       " 'ilaveten',\n",
       " \"''\",\n",
       " 'C',\n",
       " 'en',\n",
       " 'giz',\n",
       " \"''\",\n",
       " 'unvan',\n",
       " 'ın',\n",
       " 'ı',\n",
       " 'al',\n",
       " 'dı',\n",
       " 've',\n",
       " 'bu',\n",
       " 'tarih',\n",
       " 'ten',\n",
       " 'sonra',\n",
       " 'kendi',\n",
       " 'sin',\n",
       " 'e',\n",
       " '“',\n",
       " 'C',\n",
       " 'en',\n",
       " 'giz',\n",
       " 'Kağan',\n",
       " '”',\n",
       " 'veya',\n",
       " '“',\n",
       " 'C',\n",
       " 'en',\n",
       " 'giz',\n",
       " 'Han',\n",
       " '”',\n",
       " 'diye',\n",
       " 'hitap',\n",
       " 'e',\n",
       " 'dil',\n",
       " 'me',\n",
       " 'sin',\n",
       " 'i',\n",
       " 'is',\n",
       " 'te',\n",
       " 'di',\n",
       " '.',\n",
       " 'M',\n",
       " 'o',\n",
       " 'ğ',\n",
       " 'ol',\n",
       " 'toplum',\n",
       " 'u',\n",
       " ',',\n",
       " 'C',\n",
       " 'en',\n",
       " 'giz',\n",
       " 'Han',\n",
       " \"'\",\n",
       " 'dan',\n",
       " 'önce',\n",
       " 'teşkilat',\n",
       " 'sız',\n",
       " 've',\n",
       " 'düzen',\n",
       " 'siz',\n",
       " 'di',\n",
       " '.',\n",
       " '1',\n",
       " '20',\n",
       " '6',\n",
       " 'kurultay',\n",
       " 'ın',\n",
       " 'da',\n",
       " 'devlet',\n",
       " 'in',\n",
       " 'ordu',\n",
       " 've',\n",
       " 'toplumsal',\n",
       " 'teşkilat',\n",
       " 'ın',\n",
       " 'ı',\n",
       " 'düzenle',\n",
       " 'di',\n",
       " '.',\n",
       " 'C',\n",
       " 'en',\n",
       " 'giz',\n",
       " 'Han',\n",
       " ',',\n",
       " 'hükümdar',\n",
       " 'lı',\n",
       " 'ğ',\n",
       " 'ı',\n",
       " 'dönem',\n",
       " 'in',\n",
       " 'de',\n",
       " ',',\n",
       " '1',\n",
       " '20',\n",
       " '6',\n",
       " '-',\n",
       " '12',\n",
       " '27',\n",
       " 'ara',\n",
       " 'sın',\n",
       " 'da',\n",
       " ',',\n",
       " 'Kuzey',\n",
       " 'Ç',\n",
       " 'in',\n",
       " \"'\",\n",
       " 'deki',\n",
       " 'Batı',\n",
       " 'X',\n",
       " 'i',\n",
       " 'a',\n",
       " 've',\n",
       " 'J',\n",
       " 'in',\n",
       " 'Hanedan',\n",
       " 'ı',\n",
       " ';',\n",
       " 'Türki',\n",
       " 's',\n",
       " 'tan',\n",
       " \"'\",\n",
       " 'da',\n",
       " 'ki',\n",
       " 'Kara',\n",
       " 'H',\n",
       " 'ı',\n",
       " 'tay',\n",
       " ',',\n",
       " 'Mavera',\n",
       " 'ün',\n",
       " 'nehir',\n",
       " ';',\n",
       " 'Hare',\n",
       " 'z',\n",
       " 'm',\n",
       " ',',\n",
       " 'Horasan',\n",
       " 've',\n",
       " 'İ',\n",
       " 'r',\n",
       " 'an',\n",
       " \"'\",\n",
       " 'da',\n",
       " 'ki',\n",
       " 'Hare',\n",
       " 'z',\n",
       " 'm',\n",
       " 'şah',\n",
       " 'lar',\n",
       " ',',\n",
       " 'K',\n",
       " 'af',\n",
       " 'kas',\n",
       " 'ya',\n",
       " \"'\",\n",
       " 'da',\n",
       " 'ki',\n",
       " 'Gür',\n",
       " 'cül',\n",
       " 'er',\n",
       " ',',\n",
       " 'Deş',\n",
       " 't',\n",
       " '-',\n",
       " 'i',\n",
       " 'Kıp',\n",
       " 'çak',\n",
       " \"'\",\n",
       " 'tak',\n",
       " 'i',\n",
       " 'R',\n",
       " 'us',\n",
       " 'K',\n",
       " 'ne',\n",
       " 'z',\n",
       " 'lik',\n",
       " 'leri',\n",
       " ',',\n",
       " 'Kıp',\n",
       " 'çak',\n",
       " 'lar',\n",
       " 'ile',\n",
       " 'İ',\n",
       " 'dil',\n",
       " 'Bul',\n",
       " 'gar',\n",
       " 'lar',\n",
       " 'ı',\n",
       " 'üzer',\n",
       " 'in',\n",
       " 'e',\n",
       " 'sefer',\n",
       " 'ler',\n",
       " 'yap',\n",
       " 'tı',\n",
       " 've',\n",
       " 'imparator',\n",
       " 'lu',\n",
       " 'ğ',\n",
       " 'u',\n",
       " 'dönem',\n",
       " 'in',\n",
       " 'de',\n",
       " 'gerçekleş',\n",
       " 'tir',\n",
       " 'di',\n",
       " 'ğ',\n",
       " 'i',\n",
       " 'hiçbir',\n",
       " 'savaş',\n",
       " 'ı',\n",
       " 'kaybet',\n",
       " 'me',\n",
       " 'di',\n",
       " '.',\n",
       " 'Bu',\n",
       " 'n',\n",
       " 'lar',\n",
       " 'ın',\n",
       " 'son',\n",
       " 'u',\n",
       " 'cunda',\n",
       " 'Pasifik',\n",
       " 'Okyanus',\n",
       " 'u',\n",
       " \"'\",\n",
       " 'n',\n",
       " 'dan',\n",
       " 'Hazar',\n",
       " 'Deniz',\n",
       " 'i',\n",
       " \"'\",\n",
       " 'ne',\n",
       " 've',\n",
       " 'Kara',\n",
       " 'deniz',\n",
       " \"'\",\n",
       " 'in',\n",
       " 'kuzey',\n",
       " 'in',\n",
       " ...]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_tokenizer.tokenize(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "a_tokenizer = AutoTokenizer.from_pretrained(\"alibayram/tr_tokenizer\", use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['akademisyen',\n",
       " 'ler',\n",
       " 've',\n",
       " 'aile',\n",
       " 'leri',\n",
       " 'ile',\n",
       " 'birlikte',\n",
       " 'aktif',\n",
       " 'çalış',\n",
       " 'ı',\n",
       " 'yor',\n",
       " 'lar']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_tokenizer.tokenize(\"Akademisyenler ve aileleri ile birlikte aktif çalışıyorlar\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
